############
# store functions for different methods of calculating co-occurence
############
library(data.table)
library(tidyr)
library(reshape2)

# wrapper function to calculate counts values from input files
# parameters:
#@OTU_table: table with OTU abundances, rows are taxa, cols are samples
#@meta: meta data table
#@group_column: group of meta table for which to build network
#@cutoff: abundance values below cutoff will be set to 0
#var1: variable of group
#var2: variable of group
generate_counts <- function(OTU_table,meta,group_column,cutoff,fc,var1,var2,progress=F){
  
  OTUs <- rownames(OTU_table)
  #groups: all variables in the group_column
  groups <- na.exclude(unique(meta[[group_column]]))
  if (length(groups) == 1){return(NULL)}
  
  #pick OTU tables for each sample-group -> skip entries if group-label is NA there
  otus_by_group <- lapply(groups, function(x){
    samples <- na.exclude(meta[meta[[group_column]] == x,]$SampleID)
    return(data.frame(OTU_table[,samples]))
  })
  names(otus_by_group) <- groups
  if(progress){
    incProgress(1/4)
  }
  
  counts_by_group <- lapply(otus_by_group, function(x){
    return(basic_approach(x,OTUs=OTUs,cutoff=cutoff))
  })
  if(progress){
    incProgress(1/2)
  }
  
  #add option to compare one group variable against all other
  if (var2 == "all"){
    #index of var1 inside the counts_by_group list
    idx1 <- which(names(counts_by_group)==var1)
    #loop over remaining tables in list, do "compare_counts()" and combine into one data frame
    #--> this creates x edges between OTUs, with x== the number of remaining tables
    counts<-lapply(counts_by_group[c(-idx1)], function(x){
      counts_x <- compare_counts(counts_by_group[[var1]], x,fc)
      return(counts_x)
    })
    counts<-rbindlist(counts)
  }else{
    counts <- compare_counts(counts_by_group[[var1]],counts_by_group[[var2]],fc)
  }
  if(progress){
    incProgress(1/4)
  }
  #sort counts (edges) by absolute value, to display most "extreme" edges
  counts<-counts[order(abs(counts$value),decreasing = T),]
  return(counts)
}

# rows are OTU; column is sample
basic_approach <- function(table,OTUs,cutoff){
  #save OTU names
  #OTUs are in rows!
  samples <- colnames(table)
  n_otus <- length(OTUs)
  sample_size <- ncol(table)
  
  #binarization & normalization
  if(!is.data.table(table)){
    table <- as.data.table(table)
  }
  
  table[, (samples) := lapply(.SD,function(x){ ifelse(x>cutoff,1,0)}),.SDcols=samples][
    ,(samples) := lapply(.SD,function(x){return(x/1)}),.SDcols=samples]
  
  
  mat <- matrix(,nrow=n_otus,ncol=n_otus)
  table<-as.data.frame(table)
  
  start_time <- Sys.time()
  for(i in 1:n_otus){
    colsToCount <- which(table[i,] > 0)
    for(j in 1:n_otus){
      #this skips upper triangle of matrix
      if(i<j){
        next()
      }else{
        mat[i,j]<-sum(table[colsToCount,j])
      }
    }
    #set diagonale to NA
    mat[i,i]<-NA
  }
  end_time <- Sys.time()
  print(paste("Count calculation took",(end_time-start_time),"seconds."))
  
  rownames(mat)<-OTUs
  colnames(mat)<-OTUs
  
  counts<-setNames(melt(mat,na.rm = T),c("OTU1","OTU2","value"))
  return(counts)
}

# 
compare_counts <- function(tab1, tab2, type){
  #both tables have same amount of rows and same order if calculated with basic_approach()
  out_tab <- data.table(OTU1 = tab1$OTU1, OTU2 = tab1$OTU2)
  
  
  if(type==0){
    out_tab$value <- log2((tab2$value+0.001) / (tab1$value+0.001))
  }else{
    out_tab$value <- (tab1$value - tab2$value)
  }
  return(out_tab)
}

# create data table with all unique combinations, where (A,B) == (B,A)
unique_combinations <- function(l1, l2){
  t<-as.data.table(expand.grid(l1,l2))
  t$key<-apply(t, 1, function(x)paste(sort(x), collapse=''))
  t<-subset(t, !duplicated(t$key))
  t$key<-NULL
  names(t)<-c("OTU1","OTU2")
  return(t)
}


###############################
#     topological sorting     #
###############################


runTopologicalSorting<-function(otu,cutoff = 0.1){
  sourceCpp('../src/topological_sorting.cpp')
  otu_names <- rownames(otu)
  out<-lapply(otu, function(x){
      calculate_topological_sorting(x,cutoff)
  })
  out<-data.frame(out,otu=otu_names)
  return(out)
}

plot_topologies <- function(df_levels,cutoff=0.1){
  #change df to long format; keep otu column 
  df_levels_long<-gather(df_levels,sample,level,-otu)
  ggplot(data = df_levels_long,aes(x=sample))+
    geom_histogram(stat = "identity")
}

#ggplot(out_long,aes(x=reorder(otu, level),fill=sample,y=level))+geom_bar(stat="identity",color="black")+theme(axis.text.x = element_text(angle=90,size=9,vjust=0.5,hjust=0.5))+labs(x="OTUs",y="Topological sorting level (normalized by max. level per sample)")+ggtitle(" OTUs with their specific levels generated by topological sorting colored by sample \n OTUs to the left are labeled with level 0 in more samples")

##########################
#  time-series analysis  #
##########################

# this code is heavily influenced by the Rhea microbiome analysis scripts
# https://github.com/Lagkouvardos/Rhea/blob/master/5.Serial-Group-Comparisons/Over-Time-Serial-Comparisons.R
over_time_serial_comparison <- function(phylo, time_points, patient_blocks){
  data <- data.frame(cbind(phylo@sam_data, t(phylo@otu_table)))
  # remove all non-numeric columns
  d <- data[, sapply(data, is.numeric)]
  data <- cbind(data[[time_points]],data[[patient_blocks]], d)
  colnames(data)[which(colnames(data)=="data[[time_points]]")]<- time_points
  colnames(data)[which(colnames(data)=="data[[patient_blocks]]")]<- patient_blocks
  # Check if all time points are available
  bool_vec <- table(data[[patient_blocks]])==nlevels(as.factor(data[[time_points]]))
  # List with IDs without all time points
  bool_names <- names(subset(bool_vec,bool_vec==FALSE))
  
  time_points_factor <- as.factor(data[[time_points]])
  blocks_factor <- as.factor(data[[patient_blocks]])
  

  # add missing time-points to data
  d<-lapply(seq_along(1:dim(data)[1]), function(i){
    idx <- data[i, patient_blocks]
    if(idx %in% bool_names){
      bool_names <- bool_names[bool_names != idx] 
      id_sub <- data[data[[patient_blocks]]==idx,] # this is the subset of the current patient id
      # Which timepoints are already available and which time points are missing
      missing <- levels(time_points_factor)[which(levels(time_points_factor) %in% id_sub[[time_points]]==FALSE)]
      # check if block has some time-points more than once
      multiple <- dim(id_sub)[1]>nlevels(time_points_factor)
      if(multiple){
        message(paste0("Found multiple time-points for ", idx,": "))
        message(id_sub[[time_points]])
        #stop(paste0("Found multiple time-points for sample-block", idx,"; please remove them in the filtering tab."), call.=F)
      }else if(length(missing)>0){
        # add new line with NA in all fields; but add time-point and ID manually
        for(j in 1:nlevels(as.factor(missing))){
          new_row <- rep(NA, dim(data)[2])
          names(new_row) <- colnames(data)
          new_row[[time_points]] <- missing[j]
          new_row[[patient_blocks]] <- idx
          data <<- rbind(data, new_row)
        }  
      }
    }
  })
  
  time_points_factor <- as.factor(data[[time_points]])
  blocks_factor <- as.factor(data[[patient_blocks]])
  
  df <- data.frame(name=character(0), pvalue=numeric(0))
  s <- sapply(3:dim(data)[2], function(i){
    my_test_vector <- data[,i]
    my_name <- colnames(data)[i]
    
    tmp <- as.data.frame(cbind(my_test_vector,time_points_factor,blocks_factor))
    
    tmp <-  tmp[order(tmp[["time_points_factor"]], tmp[["blocks_factor"]]),]
    
    mat <- matrix(tmp[,1],nrow=nlevels(blocks_factor),ncol=nlevels(time_points_factor))
    
    mat <- mat[rowSums(is.na(mat)) !=  nlevels(time_points_factor), ]
    
    mat <- mat[rowSums(is.na(mat))==0,]
    
    fit <- friedman.test(mat)
    new_row <- data.frame(name=my_name, pvalue=round(fit$p.value,4))
    df<<-rbind(df, new_row)
  })
  
  df$corrected <- round(p.adjust(df$pvalue, method = "BH"),4)
  
  return(df)
  
}
